<!DOCTYPE html><html lang="en,default"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.2.1"><link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico"><link rel="icon" type="image/png" sizes="32x32" href="/avatar.jpg"><link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico"><link rel="mask-icon" href="/favicon.ico" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="/lib/animate-css/animate.min.css"><script class="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"hanielxx.com",root:"/",scheme:"Mala",version:"8.0.0-rc.4",exturl:!1,sidebar:{position:"right",display:"always",padding:18,offset:12},copycode:!0,bookmark:{enable:!0,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"buttons",active:"disqus",storage:!0,lazyload:!1,nav:null,activeClass:"disqus"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"fadeInDown",post_body:"fadeInDown",coll_header:"fadeInLeft",sidebar:"fadeInUp"}},prism:!1,path:"search.xml"}</script><meta name="description" content="对比学习 Contrastive Learning笔记"><meta property="og:type" content="article"><meta property="og:title" content="对比学习 Contrastive Learning"><meta property="og:url" content="https://hanielxx.com/MachineLearning/2021-11-04-contrastive-learning"><meta property="og:site_name" content="Catch Your Dream"><meta property="og:description" content="对比学习 Contrastive Learning笔记"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://i.loli.net/2021/11/04/64hSFgOjXobR1G8.png"><meta property="og:image" content="https://note.youdao.com/yws/res/1451/WEBRESOURCE5771fc6b7d648d902744782984198822"><meta property="og:image" content="https://i.loli.net/2021/11/04/AlN6zcoV9qRm45j.png"><meta property="og:image" content="https://i.loli.net/2021/11/04/hTrbPW4Jeu8fm9w.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/TKxdpW2EkfZsD7L.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/Vr8uByA5PstcQUq.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/CNcmJP5gkUsSV37.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/2oEaWngvFMzk8bR.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/Py5fTuBdYgGNzpM.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/swjqeVOHBhMxzfv.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/16vWJ5ZAt8lYoEC.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/31tQTiA79xdMp4s.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/hIsUBJw1NRqmHjb.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/bRG1BLlTHsYAVW4.png"><meta property="og:image" content="https://note.youdao.com/yws/res/1452/WEBRESOURCE98792f66f9c1ab26c9335136971fe519"><meta property="og:image" content="https://i.loli.net/2021/11/04/7lqnS4HJCGm9DTb.png"><meta property="og:image" content="https://i.loli.net/2021/11/04/6a7HUBeudJxoN29.png"><meta property="og:image" content="https://i.loli.net/2021/11/04/8CtcDhV4iEfGadQ.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/4F3WYagE57iDBXq.png"><meta property="og:image" content="https://i.loli.net/2021/11/04/8G5PeQEgoKVuJnm.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/ToZOtILmXwrbndC.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/qTvSwibDEmcXg6U.jpg"><meta property="og:image" content="https://i.loli.net/2021/11/04/2kFiv8N4HhLqGcu.png"><meta property="og:image" content="https://i.loli.net/2021/11/04/Yod7lbkiEWNZ9VD.png"><meta property="og:image" content="https://i.loli.net/2021/11/04/8vDmBTx1LKktUqo.jpg"><meta property="article:published_time" content="2021-11-04T06:34:18.000Z"><meta property="article:modified_time" content="2021-11-26T03:23:00.592Z"><meta property="article:author" content="Hanielxx"><meta property="article:tag" content="DataAugmentation"><meta property="article:tag" content="ContrastiveLearning"><meta property="article:tag" content="MoCo"><meta property="article:tag" content="SimCLR"><meta property="article:tag" content="Swav"><meta property="article:tag" content="SEER"><meta property="article:tag" content="BYOL"><meta property="article:tag" content="BatchNorm"><meta property="article:tag" content="MLP"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://i.loli.net/2021/11/04/64hSFgOjXobR1G8.png"><link rel="canonical" href="https://hanielxx.com/MachineLearning/2021-11-04-contrastive-learning.html"><script class="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"en"}</script><title>对比学习 Contrastive Learning | Catch Your Dream</title><noscript><style>body{margin-top:2rem}.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header,.use-motion .sidebar{visibility:visible}.use-motion .footer,.use-motion .header,.use-motion .site-brand-container .toggle{opacity:initial}.use-motion .custom-logo-image,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line{transform:scaleX(1)}.search-pop-overlay,.sidebar-nav{display:none}.sidebar-panel{display:block}</style></noscript><style>mjx-container[jax=SVG]{direction:ltr}mjx-container[jax=SVG]>svg{overflow:visible}mjx-container[jax=SVG]>svg a{fill:#00f;stroke:#00f}mjx-container[jax=SVG][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=SVG][justify=left]{text-align:left}mjx-container[jax=SVG][justify=right]{text-align:right}g[data-mml-node=merror]>g{fill:red;stroke:red}g[data-mml-node=merror]>rect[data-background]{fill:#ff0;stroke:none}g[data-mml-node=mtable]>line[data-line]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>rect[data-frame]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>.mjx-dashed{stroke-dasharray:140}g[data-mml-node=mtable]>.mjx-dotted{stroke-linecap:round;stroke-dasharray:0,140}g[data-mml-node=mtable]>svg{overflow:visible}[jax=SVG] mjx-tool{display:inline-block;position:relative;width:0;height:0}[jax=SVG] mjx-tool>mjx-tip{position:absolute;top:0;left:0}mjx-tool>mjx-tip{display:inline-block;padding:.2em;border:1px solid #888;font-size:70%;background-color:#f8f8f8;color:#000;box-shadow:2px 2px 5px #aaa}g[data-mml-node=maction][data-toggle]{cursor:pointer}mjx-status{display:block;position:fixed;left:1em;bottom:1em;min-width:25%;padding:.2em .4em;border:1px solid #888;font-size:90%;background-color:#f8f8f8;color:#000}foreignObject[data-mjx-xml]{font-family:initial;line-height:normal;overflow:visible}.MathJax path{stroke-width:3}mjx-container[display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}</style><link rel="alternate" href="/atom.xml" title="Catch Your Dream" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><main class="main"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="Toggle navigation bar"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><h1 class="site-title">Catch Your Dream</h1><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-algorithm"><a href="/tags/Algorithm/" rel="section"><i class="fa fa-code fa-fw"></i>Algorithm</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="Searching..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">Table of Contents</li><li class="sidebar-nav-overview">Overview</li></ul><section class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#对比学习"><span class="nav-number">1.</span> <span class="nav-text">对比学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MoCo-CVPR2020"><span class="nav-number">2.</span> <span class="nav-text">MoCo (CVPR2020)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#主要思想"><span class="nav-number">2.1.</span> <span class="nav-text">主要思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pretext-Task"><span class="nav-number">2.2.</span> <span class="nav-text">Pretext Task</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#伪代码"><span class="nav-number">2.3.</span> <span class="nav-text">伪代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SimCLR"><span class="nav-number">3.</span> <span class="nav-text">SimCLR</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#流程模拟"><span class="nav-number">3.1.</span> <span class="nav-text">流程模拟</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MoCo-v2"><span class="nav-number">4.</span> <span class="nav-text">MoCo v2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SimCLR-v2（NIPS20）"><span class="nav-number">5.</span> <span class="nav-text">SimCLR v2（NIPS20）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Swav"><span class="nav-number">6.</span> <span class="nav-text">Swav</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SEER"><span class="nav-number">7.</span> <span class="nav-text">SEER</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BYOL"><span class="nav-number">8.</span> <span class="nav-text">BYOL</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据增强方式"><span class="nav-number">9.</span> <span class="nav-text">数据增强方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BatchNorm的影响"><span class="nav-number">10.</span> <span class="nav-text">BatchNorm的影响</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MLP在里面的作用"><span class="nav-number">11.</span> <span class="nav-text">MLP在里面的作用</span></a></li></ol></div></section><section class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Hanielxx" src="/avatar.jpg"><p class="site-author-name" itemprop="name">Hanielxx</p><div class="site-description" itemprop="description">Hanielxx | Blog</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">150</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">8</span> <span class="site-state-item-name">categories</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">235</span> <span class="site-state-item-name">tags</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/HanielF" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;HanielF" rel="external nofollow noopener noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:hanielxx@outlook.com" title="E-Mail → mailto:hanielxx@outlook.com" rel="external nofollow noopener noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div></section></div></aside><div id="sidebar-dimmer"></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><div class="reading-progress-bar"></div><a role="button" class="book-mark-link book-mark-link-fixed"></a> <a href="https://github.com/HanielF" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="external nofollow noopener noreferrer" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><noscript><div id="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en"><link itemprop="mainEntityOfPage" href="https://hanielxx.com/MachineLearning/2021-11-04-contrastive-learning"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/avatar.jpg"><meta itemprop="name" content="Hanielxx"><meta itemprop="description" content="Hanielxx | Blog"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Catch Your Dream"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">对比学习 Contrastive Learning</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Created: 2021-11-04 14:34:18" itemprop="dateCreated datePublished" datetime="2021-11-04T14:34:18+08:00">2021-11-04</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">Edited on</span> <time title="Modified: 2021-11-26 11:23:00" itemprop="dateModified" datetime="2021-11-26T11:23:00+08:00">2021-11-26</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">In</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MachineLearning/" itemprop="url" rel="index"><span itemprop="name">MachineLearning</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Disqus: </span><a title="disqus" href="/MachineLearning/2021-11-04-contrastive-learning#disqus_thread" itemprop="discussionUrl"><span class="post-comments-count disqus-comment-count" data-disqus-identifier="MachineLearning/2021-11-04-contrastive-learning.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="Symbols count in article"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">Symbols count in article: </span><span>4.9k</span> </span><span class="post-meta-item" title="Reading time"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">Reading time &asymp;</span> <span>12 mins.</span></span></div></header><div class="post-body" itemprop="articleBody"><meta name="referrer" content="no-referrer"><div class="note info"><p>对比学习 Contrastive Learning笔记</p></div><a id="more"></a><h2 id="对比学习"><a href="#对比学习" class="headerlink" title="对比学习"></a>对比学习</h2><p>记住的事物特征，不一定是像素级别的，而是更高维度的。更具体来说，比如用编码去做分类任务，我们不需要知道每个数据的细节，只要抓住每个类别的主要特征，自然就能把他们分开了。</p><p>不重构数据，那如何衡量表示 Z的好坏呢？这时也可以用互信息 I(X,Z)，代表我们知道了 Z之后，X 的信息量减少了多少。 如果对最大化互信息的目标进行推导，就会得到对比学习的loss（也称InfoNCE），其核心是通过计算样本表示间的距离，拉近正样本，拉远负样本。也就是说，当我们能够区分该样本的正负例时，得到的表示就够用了。</p><p>具体的做法是，输入N个图片，用不同的数据增强方法为每个图片生成两个view，每个图片的两个不同aug方式，就作为正样本，分别对它们编码得到y和y’。我们对上下两批表示两两计算cosine，得到NxN的矩阵，每一行的对角线位置代表y和y’的相似度，其余代表y和N-1个负例的相似度。</p><p><img src="https://i.loli.net/2021/11/04/64hSFgOjXobR1G8.png" alt="64hSFgOjXobR1G8"></p><p>摘自<a href="https://zhuanlan.zhihu.com/p/334732028" target="_blank" rel="external nofollow noopener noreferrer">知乎</a></p><h2 id="MoCo-CVPR2020"><a href="#MoCo-CVPR2020" class="headerlink" title="MoCo (CVPR2020)"></a>MoCo (CVPR2020)</h2><h3 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h3><ul><li>维护一个queue（可以比minibatch大很多），里面放的都是负样本，每次都对这个queue里面的做对比学习。存在queue里面embedding更新的问题，因为迭代过程中，queue里面的是不更新的，就带来不一致的问题。所以提出momentum update，做的就是用一个系数，让队列里面的embed缓慢更新，更加平滑。</li></ul><p><img src="https://note.youdao.com/yws/res/1451/WEBRESOURCE5771fc6b7d648d902744782984198822" alt="image.png"></p><p>还尝试了三种不同的方式，不同就是键值的保持和键值编码器的更新方式不同</p><p><img src="https://i.loli.net/2021/11/04/AlN6zcoV9qRm45j.png" alt="AlN6zcoV9qRm45j"></p><ul><li>a方法，字典大小和mini-batch大小相同，受限于GPU显存，对大的mini-batch进行优化也是挑战，有些pretexts进行了一些调整，能够使用更大的字典，但是这样不方便进行迁移使用</li><li>b方法，Memory Bank包含数据集所有数据的特征表示，从Memory Bank中采样数据不需要进行反向传播，所以能支持比较大的字典，然而一个样本的特征表示只在它出现时才在Memory Bank更新，所以一个epoch只会更新一次，但模型在训练过程中不断迭代，这个特征就会“过时”，因此具有更少的一致性，而且它的更新只是进行特征表示的更新，不涉及encoder。</li></ul><h3 id="Pretext-Task"><a href="#Pretext-Task" class="headerlink" title="Pretext Task"></a>Pretext Task</h3><p>将一对查询query和以及键值key组成样本对，如果它们出自同一图像，那么是正样本对，否则为负样本对。查询和键值分别编码自 fq 和 fk。在随机数据增强下从同一图像中任意提取两个”view”构建正样本对，负样本取自队列。</p><p>Technical details. 使用ResNet作为编码器，最后一层输出为128D向量，即查询query和键值key的表示。</p><p>Shuffling BN. 在实验中发现Batch Norm会阻止模型学到良好的特征表示。模型似乎会欺骗pretext task并容易找到低损失的解决方案。可能是因为由BN导致的intra-batch communication among samples泄露了信息。</p><p>作者通过Shuffling BN来解决该问题。在训练时使用多个GPU，在每个GPU上分别进行BN（常规操作），对于键值编码器 fk ，在当前mini-batch中打乱样本的顺序，再把它们送到GPU上分别进行BN，然后再恢复样本的顺序；对于查询编码器 fq，不改变样本的顺序。这能够保证用于计算查询和其正键值的批统计值出自两个不同的子集。</p><h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><p><img src="https://i.loli.net/2021/11/04/hTrbPW4Jeu8fm9w.jpg" alt="hTrbPW4Jeu8fm9w"></p><h2 id="SimCLR"><a href="#SimCLR" class="headerlink" title="SimCLR"></a>SimCLR</h2><p>摘自<a href="https://segmentfault.com/a/1190000039942131" target="_blank" rel="external nofollow noopener noreferrer">segmentfault</a><br>对比学习的目标是让相似样本产生相同的表示，不相似的样本产生不同的表示。对比学习的核心是噪声对比估计损失（Noise Contrastive Estimator (NCE) loss），其其表示如下：</p><p><img src="https://i.loli.net/2021/11/04/TKxdpW2EkfZsD7L.jpg" alt="TKxdpW2EkfZsD7L"></p><p>其中x+是输入x的相似点，(x,x+)又可称为正对。通常x+由x变换得来，如图像裁剪，旋转变换或其他的数据增广手段。反之，x-则是x的不相似样本，则有负对(x,x-)，NCE loss会使得负对与正对区别开。一般对于每组正对，都会有K组负对。负对的数目对对比学习效果影响很大。</p><p>sim(.)代表相似度度量。通常其使用内积或余弦相似度。g(.)是一个卷积神经网络。有的对比学习会用siamese网络。</p><p><img src="https://i.loli.net/2021/11/04/Vr8uByA5PstcQUq.jpg" alt="Vr8uByA5PstcQUq"></p><h3 id="流程模拟"><a href="#流程模拟" class="headerlink" title="流程模拟"></a>流程模拟</h3><ol><li>首先，我们从原始图像生成批大小为N的batch。为了简单起见，我们取一批大小为N = 2的数据。在论文中，他们使用了8192的大batch</li><li>论文中定义了一个随机变换函数T，该函数取一幅图像并应用 <code>random (crop + flip + color jitter + grayscale)</code>。对于这个batch中的每一幅图像，使用随机变换函数得到一对图像。因此，对于batch大小为2的情况，我们得到2N = 4张总图像。<img src="https://i.loli.net/2021/11/04/CNcmJP5gkUsSV37.jpg" alt="CNcmJP5gkUsSV37"></li><li>每一对中的增强过的图像都通过一个编码器来获得图表示。所使用的编码器是通用的，可与其他架构替换。下面显示的两个编码器有共享的权值，我们得到向量<code>$h_i$</code>和<code>$h_j$</code>。可以参考上面的图。论文里面用ReNet-50作为ConvNet编码器，输出2048维向量h</li><li>Dense layer部分是MLP，linear-bn-relu-linear-bn，非线性变换。<strong>研究发现encoder编码后的 h 会保留和数据增强变换相关的信息，而非线性层的作用就是去掉这些信息，让表示回归数据的本质。注意非线性层只在无监督训练时用，在迁移到其他任务时不使用</strong></li><li>计算两两间的余弦相似度</li><li>计算损失，SimCLR使用NT-Xent损失：归一化温度-尺度交叉熵损失。</li></ol><p><img src="https://i.loli.net/2021/11/04/2oEaWngvFMzk8bR.jpg" alt="2oEaWngvFMzk8bR"></p><p>这个softmax计算等价于第二个增强的猫图像与图像对中的第一个猫图像最相似的概率。这里，batch中所有剩余的图像都被采样为不相似的图像(负样本对)。然后，通过取上述计算的对数的负数来计算这一对图像的损失。这个公式就是噪声对比估计(NCE)损失：</p><p><img src="https://i.loli.net/2021/11/04/Py5fTuBdYgGNzpM.jpg" alt="Py5fTuBdYgGNzpM"></p><p><img src="https://i.loli.net/2021/11/04/swjqeVOHBhMxzfv.jpg" alt="swjqeVOHBhMxzfv"></p><p>在图像位置互换的情况下，我们再次计算同一对图像的损失。</p><p><img src="https://i.loli.net/2021/11/04/16vWJ5ZAt8lYoEC.jpg" alt="16vWJ5ZAt8lYoEC"></p><p>最后，我们计算Batch size N=2的所有配对的损失并取平均值。</p><p><img src="https://i.loli.net/2021/11/04/31tQTiA79xdMp4s.jpg" alt="31tQTiA79xdMp4s"><br>7. 结果：在ImageNet ilsvvc -2012上，实现了76.5%的top-1准确率，比之前的SOTA自监督方法Contrastive Predictive Coding提高了7%，与有监督的ResNet50持平。当训练1%的标签时，它达到85.8%的top-5精度，超过了AlexNet，但使用带标签的数据少了100倍。</p><p><img src="https://i.loli.net/2021/11/04/hIsUBJw1NRqmHjb.jpg" alt="hIsUBJw1NRqmHjb"></p><h2 id="MoCo-v2"><a href="#MoCo-v2" class="headerlink" title="MoCo v2"></a>MoCo v2</h2><p><img src="https://i.loli.net/2021/11/04/bRG1BLlTHsYAVW4.png" alt="bRG1BLlTHsYAVW4"></p><h2 id="SimCLR-v2（NIPS20）"><a href="#SimCLR-v2（NIPS20）" class="headerlink" title="SimCLR v2（NIPS20）"></a>SimCLR v2（NIPS20）</h2><p><img src="https://note.youdao.com/yws/res/1452/WEBRESOURCE98792f66f9c1ab26c9335136971fe519" alt="image.png"></p><h2 id="Swav"><a href="#Swav" class="headerlink" title="Swav"></a>Swav</h2><p><img src="https://i.loli.net/2021/11/04/7lqnS4HJCGm9DTb.png" alt="7lqnS4HJCGm9DTb"></p><p>上面的都是把每个样本作为一类来看的，但是这样耗时也比较耗资源，就提出了一个新想法，在minibatch里面聚类，然后只要区分每个类的类簇就可以。每个类簇里面的样本按道理应该要和类簇的相似度为1，但是这样太严格了，用soft label更好点，这也就是是上图的Codes。</p><p>除了这个，还提出一种新的数据增强方式：mix不同分辨率的view。</p><p><img src="https://i.loli.net/2021/11/04/6a7HUBeudJxoN29.png" alt="6a7HUBeudJxoN29"></p><h2 id="SEER"><a href="#SEER" class="headerlink" title="SEER"></a>SEER</h2><ol><li>就是Swav作者做的新活</li><li>就是数据集更大了，然后模型更好了。</li><li>用了10亿的Instagram图片训练，然后用ResNet结合了一点神经网络搜索NAS</li><li>不细看了</li><li><img src="https://i.loli.net/2021/11/04/8CtcDhV4iEfGadQ.jpg" alt="8CtcDhV4iEfGadQ"></li></ol><h2 id="BYOL"><a href="#BYOL" class="headerlink" title="BYOL"></a>BYOL</h2><p><img src="https://i.loli.net/2021/11/04/4F3WYagE57iDBXq.png" alt="4F3WYagE57iDBXq"></p><ol><li>上面的都需要负样本，这提出在没有负样本的情况下做constrastive learning。</li><li>和SimCLR，MoCo区别<ol><li>SimCLR提出了nonlinear projection head的概念，nonlinear projection head里面没有BN；</li><li>SimCLR提取两张经过augmentation的图片的CNN网络是相同的，而MOCO训练的时候则是有两个不同的网络， 其中一个网络根据另一个网络的parameters慢慢进行更新，且这个网络会提供一个memory bank，会提供更多大量的negative sample。因为contrastive learning是非常依仗negative sample的数量，所以negative sample数量越多，contrastive task越难，最终提取到的representation就越好。</li><li>BYOL则是在MOCO的基础上直接去掉了negative sample。如下图所示，前面的结构都和MOCO相同（除了 g theta 的结构，加入了BN，后面会提到），两个不同的网络分别为上面的online网络和target网络。不同之处是online网络在经过projection得到 z theta 后加了一个predictor（由1层或2层FC组成），然后用这个predictor来预测target网络得到的 z’ ，相当于一个回归任务，loss函数采用MSE（值得注意的是，z theta 和 z’ 都经过了L2 normalize）</li></ol></li><li><img src="https://i.loli.net/2021/11/04/8G5PeQEgoKVuJnm.jpg" alt="8G5PeQEgoKVuJnm"></li><li><img src="https://i.loli.net/2021/11/04/ToZOtILmXwrbndC.jpg" alt="ToZOtILmXwrbndC"></li><li>没有负样本是非常奇怪的，因为loss就是为了从负样本和正样本中选出那个正样本。一般用的那个softmax cross entropy loss可以芬姐成两个部分。<img src="https://i.loli.net/2021/11/04/qTvSwibDEmcXg6U.jpg" alt="qTvSwibDEmcXg6U">这个意思就是说，我可以把contrastive loss分解成两个部分，第一部分叫做alignment，就是希望positive pair的feature接近，第二部分叫做uniformity，就是希望所有点的feature尽量均匀的分部在unit sphere上面，都挺好理解的吧？这两部分理论上是都需要的，假如只有alignment，没有uniformity，那就很容易都坍缩到０，就是退化解。所以BYOL就是去掉uniformity，只保留了alignment。这听起来似乎不科学，因为模型很容易学到trivial solution：就是使online网络和target网络永远都输出同样的constant。所以模型为什么会work呢？看了一些大佬的分享（详见Reference），总结大概有以下几点：<strong>EMA，predictor，BN</strong>。</li><li>关于EMA（exponential moving average）<ol><li>详细的EMA，看这里<a href="https://zhuanlan.zhihu.com/p/68748778" target="_blank" rel="external nofollow noopener noreferrer">EMA的原理和实现</a></li><li>MA可能在帮助悄悄scatter feature，因为τ取值比较大时，target网络的更新是比较慢的，迭代次数较多的时候，使得online network和target network是不同的，进而帮助阻止模型塌陷</li></ol></li><li>Predictor，后面接的那个全连接层，会让online net输出和target不那么一样，而是靠ffn来match，比较灵活</li><li>BN层<ol><li>BYOL是在MoCo基础上做的，但是相比来说加入了BN层</li><li>BN实际上就是规范化一个batch的分布。得到的mean和variance都和batch里面所有的image有关，所以BN相当于一个隐性的contrastive learning：每一个image都和batch的mean做contrastive learning。</li><li><img src="https://i.loli.net/2021/11/04/2kFiv8N4HhLqGcu.png" alt="2kFiv8N4HhLqGcu"></li><li>从uniformity的角度来理解，BN会把不同点的特征scatter开来，就等于默默地在做dispersion。正是因为在BN之后，batch中的所有样本都不能采用相同的值，所以可以防止模型坍塌。</li><li>复现结果来看，没有BN的话，结果和random baseline差不多，并且没有BN的时候，online net和target是非常像的</li></ol></li></ol><h2 id="数据增强方式"><a href="#数据增强方式" class="headerlink" title="数据增强方式"></a>数据增强方式</h2><ol><li>Si吗CLR中提出，不同的增强方式组合会更好，单一增强太简单。并且Crop和Color的组合最好，因为大多数图像中的颜色是比较一致的，即使裁剪也会容易辨认，如果去掉颜色会增加任务难度</li><li>颜色越浅，效果越好，分数越高。<img src="https://i.loli.net/2021/11/04/Yod7lbkiEWNZ9VD.png" alt="Yod7lbkiEWNZ9VD"></li></ol><h2 id="BatchNorm的影响"><a href="#BatchNorm的影响" class="headerlink" title="BatchNorm的影响"></a>BatchNorm的影响</h2><p>BatchNorm导致的信息泄露</p><ul><li>在分布式训练中，BN都是分别在各个设备上做的。而对比学习的正例对在一个机器上计算，会出现信息泄露。个人认为，在BN去除batch内共同特征时，很可能被归一化到相似的分布，降低任务难度。</li><li>MoCo的解决办法是把一边的样本重新shuffle再并行，另一边顺序不变，这样batch的统计量就不同了；SimCLR的解法是计算一个全局的BN值。</li></ul><h2 id="MLP在里面的作用"><a href="#MLP在里面的作用" class="headerlink" title="MLP在里面的作用"></a>MLP在里面的作用</h2><p>在SimCLR以后的工作中都使用了MLP，SimSiam也对它的作用进行了探究：<br><img src="https://i.loli.net/2021/11/04/8vDmBTx1LKktUqo.jpg" alt="8vDmBTx1LKktUqo"></p><p>没有MLP的时候很差，<strong>MLP可能承担了估计整体期望的功能</strong>，这同SimCLR最初增加MLP时的发现是一致的，核心思想还是过滤表示中的无效特征，得到本质，服务于“对比”任务。</p><p><strong>上面大部分内容摘自<a href="https://zhuanlan.zhihu.com/p/334732028" target="_blank" rel="external nofollow noopener noreferrer">自监督对比学习（Contrastive Learning）综述+代码</a>以及上面提到的几篇博客</strong></p></div><footer class="post-footer"><div class="post-tags"><a href="/tags/DataAugmentation/" rel="tag"><i class="fa fa-tag"></i> DataAugmentation</a> <a href="/tags/ContrastiveLearning/" rel="tag"><i class="fa fa-tag"></i> ContrastiveLearning</a> <a href="/tags/MoCo/" rel="tag"><i class="fa fa-tag"></i> MoCo</a> <a href="/tags/SimCLR/" rel="tag"><i class="fa fa-tag"></i> SimCLR</a> <a href="/tags/Swav/" rel="tag"><i class="fa fa-tag"></i> Swav</a> <a href="/tags/SEER/" rel="tag"><i class="fa fa-tag"></i> SEER</a> <a href="/tags/BYOL/" rel="tag"><i class="fa fa-tag"></i> BYOL</a> <a href="/tags/BatchNorm/" rel="tag"><i class="fa fa-tag"></i> BatchNorm</a> <a href="/tags/MLP/" rel="tag"><i class="fa fa-tag"></i> MLP</a></div><div class="post-nav"><div class="post-nav-item"><a href="/Papers/2021-11-04-support-set-video-text" rel="prev" title="论文笔记 | Support-set bottlenecks for video-text representation learning"><i class="fa fa-chevron-left"></i> 论文笔记 | Support-set bottlenecks for video-text representation learning</a></div><div class="post-nav-item"><a href="/Notes/2021-11-05-cikm-qq-competition" rel="next" title="2021-CIKM-QQ浏览器AI算法大赛-赛后分享会笔记">2021-CIKM-QQ浏览器AI算法大赛-赛后分享会笔记 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comment-button-group"><a class="btn comment-button disqus">disqus</a> <a class="btn comment-button gitalk">gitalk</a></div><div class="comment-position disqus"><div class="comments"><div id="disqus_thread"><noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript></div></div></div><div class="comment-position gitalk"><div class="comments" id="gitalk-container"></div></div><script>(function() {
          let commentButton = document.querySelectorAll('.comment-button');
            commentButton.forEach(element => {
            let commentClass = element.classList[2];
            element.addEventListener('click', () => {
              commentButton.forEach(active => active.classList.toggle('active', active === element));
              document.querySelectorAll('.comment-position').forEach(active => active.classList.toggle('active', active.classList.contains(commentClass)));
              if (CONFIG.comments.storage) {
                localStorage.setItem('comments_active', commentClass);
              }
            });
          });
          let { activeClass } = CONFIG.comments;
          if (CONFIG.comments.storage) {
            activeClass = localStorage.getItem('comments_active') || activeClass;
          }
          if (activeClass) {
            let activeButton = document.querySelector(`.comment-button.${activeClass}`);
            if (activeButton) {
              activeButton.click();
            }
          }
        })();</script><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Haniel Farnsworth</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span class="post-meta-item-text">Symbols count total: </span><span title="Symbols count total">582k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">Reading time total &asymp;</span> <span title="Reading time total">24:15</span></div><div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="external nofollow noopener noreferrer" target="_blank">Hexo</a> & <a href="https://github.com/next-geek/next-geek" class="theme-link" rel="external nofollow noopener noreferrer" target="_blank">Next-geek</a></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script src="/js/local-search.js"></script><script>function loadCount(){var d=document,n=d.createElement("script");n.src="https://hanielxx.disqus.com/count.js",n.id="dsq-count-scr",(d.head||d.body).appendChild(n)}window.addEventListener("load",loadCount,!1)</script><script>var disqus_config = function() {
    this.page.url = "https://hanielxx.com/MachineLearning/2021-11-04-contrastive-learning";
    this.page.identifier = "MachineLearning/2021-11-04-contrastive-learning.html";
    this.page.title = "对比学习 Contrastive Learning";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://hanielxx.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"><script>NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '27e3eba13ef3780f492b',
      clientSecret: '4e28d0b26bbf1501e220a7d94b983aec4e4c11df',
      repo        : 'CommentsRepo',
      owner       : 'HanielF',
      admin       : ['HanielF'],
      id          : '40fe29c51a6bddaf5c0f540dd36836b2',
        language: 'en',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});</script></body></html>